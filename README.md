## 为飞书聊天机器人度身定制的AI智能助手后端项目，集成(几乎)所有大模型，在飞书聊天窗口中调用Multi Agent完成复杂任务。同时提供统一模型调用接口。

### 本项目只是个纯代码分享，不涉及任何账号申请、账号共享等内容，您需要自行解决账号问题。

### 本项目的开发理念：与AI的对话方式应该尽量自然，而最自然的交互方式，就是聊天工具的聊天窗口。而在所有的聊天工具里，飞书又是最自然的。因为：
1. 它是唯一一个实现了流式打字效果输出的聊天工具，并且完全开放了API。
2. 自然解决了用户管理和权限问题，如果没有特殊需求，项目不需要自行处理这些问题。
3. 自然解决了聊天记录管理的问题。

因此，本项目几乎是专为飞书而生，部署后新建一个飞书机器人，把机器人的权限开通好，消息通知地址加上，立即可用。

基于前面的自然交互的理由，本项目目前也不支持把机器人加入到群里面去聊天，仅支持一对一私聊。因为在群里不可能理清楚上下文。

在聊天窗口需要放一个开启新会话的按钮，让用户主动截断对话，因为聊天窗口是连续的，程序并不知道什么时候应该截断对话开始新的上下文。

### 项目亮点（自我感觉）：
1. 几乎支持大模型API支持的所有功能，并第一时间跟进新的API接口与模型支持。对于飞书卡片无法正常显示的mermaid流程图，markmap思维导图，Latex数学公式都进行了解决，虽然不能改变飞书卡片，但用其它办法做了方便的实现。如果模型返回HTML代码，也可以在飞书里直接点击预览网页效果，不需要手工复制代码创建本地HTML文件。
2. 实现了一些简单Agent功能：包括自动按章节拆书总结，自动抓取网页内容进行问答，通过Function call自动查询天气、自动调用搜索引擎进行回答、自动调用画图模型（能够让GPT和Claude自动调用Midjurney或Ideogram并支持连续对话增量画图）、用代码进行数学表达式计算获得精确结果，还能直接把数据返回飞书卡片支持格式直接显示成动态可交互的图表（支持柱状图、折线图、饼图）。如果模型返回了SVG代码，会尝试在服务器端自动转成一张图片并发送到飞书。
3. 还有几个高级Agent功能：比如自动拆解任务并多次调用搜索引擎查询不同的主题，最后汇总结果生成一份报告；在服务器端打开一个虚拟浏览器打开指定的网站进行自动化操作来完成用户的指令；以搜索或收集信息过程中将计划和分步骤结果写入到服务器端的一个markdown文件中，并发送到飞书；以及一个更高层的Agent可以调度其它所有Agent来完成复杂任务。(Agent越复杂，对模型本身的能力依赖越高，需要使用GPT4o或者Claude 3.7。虚拟浏览器功能只有Claude 3.7支持。）
4. 增加新模型和新Agent非常容易，复杂的Function call递归调用系统已经自动处理了，不用去关心。
5. 虽然是为飞书而生，但仍然提供了WebApi接口，可以用来接入到自己的网页、小程序、各种原生App等等任何地方（每种项目我都有实际跑通的示例可证），而且Web端还多两个高级功能，返回文字回答的时候可以同时返回文字转语音，实现实时朗读（利用MiniMax的流式转语音功能，效果非常棒），还有封装了多家websocket接口为统一websocket接口，可以实现诸如实时语音识别成文字、实时双向翻译、OpenAI的realtime实时语音聊天接口等等接口的大一统。
6. 可以很方便的接到很多个飞书机器人的后面，每个机器人负责某一个专一功能，比如专门读书的，专门使用浏览器的，等等。
![效果预览](readme/preview.png)

### 功能演示：

https://github.com/user-attachments/assets/a29df0b9-abe6-44c1-9058-22b3bfe6cada


https://github.com/user-attachments/assets/e5be25e6-5a42-478b-8e9b-43a18923bd72


https://github.com/user-attachments/assets/de664d6f-b5cf-42ed-979e-e5a394b31596



### 项目部署方式：
一定要有Docker！

要有一台能编译和运行Docker镜像的服务器，并且有域名能够被外网正常访问。使用二阶段编译，除了docker不依赖任何编译环境。

本项目运行需要一个Mysql和一个Redis，有专用的最好，没有的话在本机用Docker启动两个也可以，只要项目能连的上就行。（Redis是存储上下文的，如果Redis重启丢数据那当前的上下文就丢了。）

Mysql最好也能远程连接或者有其它管理界面，因为提示词模板和Function定义需要手动添加到这两个表里去，我没有做管理工具。

自己要有各家大模型公司的账号，以及可正常访问其服务器的方式。（走其它聚合API接口也可以，但不保证好用。建议直接将Docker部署在海外的服务器上，或者使用nginx自建海外的转发服务器。）

1. git clone 项目
2. git checkout -b xxx  #创建一个新的分支
3. 在这个新分支下修改配置文件，也可以修改代码来满足自己的需求。也可以提交自己的文件push到自己的Git服务器。当我更新了主项目的时候你只要拉一下项目，然后把master分支往自己的分支合并一下就行了，就可以既保持主项目同步，又能管理自己的文件。

3.1 要有一个飞书机器人，并申请了所必须的权限，没有的话可以新创建一个。所需要的权限列表在readme目录下的permissions.json里。不是全都需要，但最好都加上。
   
3.2 把config.example.json文件复制成config.json文件，修改其中的所有关键信息。

3.3 改完以后运行builddocker.sh脚本编译并打包docker镜像。

3.4 如果需要在别的地方运行，把image push过去，如果在本地运行，docker run -p 8080:8080 就可以体验一下了。(如果mysql和redis也运行在本地容器里，并且使用容器名字作为连接字符串，别忘了加上--link mysql:mysql --link redis:redis 参数。）

3.5 把这个端口用任何方式映射到外网可访问，去配置飞书机器人的消息通知地址。在飞书开放平台机器人管理界面，事件与回调，事件配置和回调配置两个页面的请求地址都是 https://你的访问域名/api/ai/feishu/event
，只要地址能保存成功，基本上就没问题了。在事件配置里订阅两个事件：im.message.receive_v1，application.bot.menu_v6，在回调配置里订阅一个事件：card.action.trigger。

6. 给飞书配置几个菜单，建议使用悬浮式菜单。至少需要一个『新会话』按钮，事件名称是menu_startnewcontext，一个切换模型的按钮，事件名称是menu_to_all，也可以将几个指定模型设为快捷菜单来快速切换，事件名称是menu_to_x 把x换成这个模型的枚举值对应的数字即可。

   以下两步不是必须的：
8. 然后需要往chatgptprompts，然后给飞书菜单上再配一个提示词模板的按钮，可以将一些COT之类的复杂提示词变成一个按钮，用户点一下再输入自己的简单问题就可以了。当然不配置模板也不影响使用。
9. 需要往chatgptfunctions里添加几个Function定义，这样内置的Function才会起作用。你也可以尝试调整Function的描述和触发词，但参数名称不要改。
   
（在readme目录下有两个excel文件，你可以直接导进去。另外有个建议的菜单配置文件可以作为参考。）

如果你不想使用容器，它也是可以本地直接运行的，但对服务器环境可能有些要求，推荐使用Ubuntu 22，需要在服务器上安装.Net 8 SDK，参考 https://learn.microsoft.com/zh-cn/dotnet/core/install/linux?WT.mc_id=dotnet-35129-website

并使用Dockerfile里的RUN命令，安装google-chrome-stable，解压并移动 chromedriver_linux64.zip ，中文字体fonts-arphic-uming，npm, 以及通过npx安装 playwright。以及复制fonts/*文件和刷新字体缓存。

（如果不使用浏览器控制，和服务器端生成PDF、SVG功能的话，服务器上可以什么都不用装，直接dotnet run就行。）

这些装完以后，可以直接在项目目录下运行命令dotnet run，就可以以debug模式启动项目，并使用 5141 端口。

然后可以运行 dotnet publish --property WarningLevel=0 -c Release -o bin/out

再把config.json复制到bin/out目录，然后cd进入bin/out，运行 dotnet AI_Proxy_Web.dll 就可以以生产模式运行。如果要以后台模式运行，后面加上 & 就可以了。不然退出终端的时候程序就被退出了。

### 配置文件说明

```json
{
  "Site": {
    "Host": "https://xxx/",  //通过什么域名可以访问到这个容器，可以带路径，一定要/结尾
    "MasterToken": "Ya" //用来保护WebApi接口的Token，在你想开发自己的权限处理方式之前，生成一个复杂Token放在这儿，可以用这个Token来请求Api接口
  },
  "Connection": {
    "DB": "xx", //Mysql标准连接字符串,如 server=xxx;database=xxx;uid=xxx;pwd=xxx;SslMode=none
    "Redis": "xx"  //Redis标准连接字符串，如 192.168.0.10:6379
  },
  "AliOss": { //阿里云OSS的配置，个别模型上传图片时必须用地址，才需要用到这个功能，没有可以直接忽略
    "Endpoint": "xx",
    "AccessKey": "",
    "AccessSecret": "",
    "BucketName": ""
  },
  "Instruction": "xx", //自动加在提示词的System部分的介绍，可以用于限定AI回答使用的名字、回答的风格、甚至一些内置的知识都可以
  "FeiShu": { //飞书机器人的配置，可以只配置Main这一个，Book是用来让你自行添加多个其它机器人的时候的参考，只需要复制一个BookFeishuService，复制一个BookFeishuController，改一点里面的内容就可以了。
    "Main": {
      "AppId": "cli_",
      "AppSecret": ""
    },
    "Book": {
      "AppId": "cli_",
      "AppSecret": ""
    }
  },
  "UserLevel": { //有些模型可能你不想让公司所有人看到，可以配置权限级别，数字随便写，跟下面的模型后面的数字是对应的。
    "xx": 50, //前面的xx是飞书里面的用户ID，在飞书后台的组织架构中可以查看每个人的user_id，注意不是OpenId。飞书发过来的消息里也都有每个人的user_id，后面的数字就是他的权限级别。
    "xxx": 100 //这里只需要添加高级别用户，不添加的都默认为0
  },
  "ModelUsed": {
    "GPT4o_Mini": 1, //哪些模型需要开启可见。因为项目接了所有模型，但实际上有些可能暂时没价值，或暂时不想让别人看到。只有在这里添加了的才会在他的飞书上显示出来可选。
    "GPT4o": 10, //前面是模型的ID，不是Name，也就是枚举值M里面的名字，后面的数字如果1就是所有人可见，如果大于1，就只有上面的用户权限>=它的才可见。如果是0就不可见了。虽然不可见，但API仍然可以通过这个模型ID来调用它。
  }
}
```
后面就是各个模型的地址和Key等等，看情况配置，没有配置Key的，上面也不要加为可用。建议至少配置：MiniMax+GoogleSearch，才能使用深度搜索功能（该功能会用到JinaAI，但Jina不需要Key，是免费服务）。配置Claude，才能使用浏览器控制功能。配置Gemini，才能使用长文阅读和连续对话画图功能。（Gemini和GoogleSearch只要你不绑定付款方式，就可以免费使用。）

大部分公司模型名称是统一的，不用配置，只有豆包（火山引擎）每个人看到的模型ID是不一样的，需要配置。还有的公司有两套验证机制，所以不同的功能可能要配置多个Key。

### 关于Function call功能的说明
自己开发AI客户端的最大好处，就是可以跟自己的业务系统结合，比如公司的管理者可以直接向飞书机器人提问，公司今天的业绩怎么样，不但可以直接获取数据并人性化的回复，甚至可以直接返回各部门销售额柱状图或饼图的飞书卡片。另外也可以加个自动化Job，比如每天下午5点自动把当天业绩说明和图表发到领导的飞书上。

本项目将Function Call定义成三种类型，前端类型，后端类型，和内部类型。
1. 前端类型就是这个Function大模型只负责返回调用方式，并不关心它的执行结果，比如画图表这件事，大模型只返回图表的参数，怎么画出来是要自己解决的，在飞书里面调用的时候要把它返回的参数变成飞书图表卡片并通过发消息的方式发给用户，如果是在Web端调用就把返回参数变成网页图表需要的格式调用JS就可以了。所以不同的前端Function在飞书端需要用特定的代码实现，网页端需要在JS端实现。
2. 后端类型是通过HTTP请求外部网址，通常就是业务系统的数据接口或功能接口，比如获取销售额数据， 发表一篇文章等等。只需要在数据库里添加Function的说明和参数，以及要调用的URL就可以了，不需要改代码。
3. 内部函数是指返回的Function需要在本次请求中递归调用，可能是调用另一个大模型，比如让GPT4o自动调用搜索引擎，搜索结果需要自动返回给GPT来回答你的问题。或者GPT去调用画图模型画一张图片，但画图完成这次请求就结束了，并不需要返回GPT再做一次回答。这个具体的功能也是需要写代码来实现的，数据库里添加的只是一条让大模型能够触发Function call的定义。

   所以，如果是后端方法，直接在数据库里添加一条定义就可以。如果是前端或内部函数，需要先实现代码再把Function定义添加到数据库中。

   为了避免一次提交多条Function会导致GPT错误识别，触发错误的Function，所以增加了关键字判断，只有用户的问题中包含了指定的关键字，这条Function才会被加到本次请求里。

   
### 初次开源，水平一般，请多多包涵，共同交流，共同进步。
项目问题、AI爱好者、开发爱好者，欢迎进飞书群交流。

<img src="https://github.com/unfish/AI_Proxy_United/blob/master/readme/feishugroup.png?raw=true" width="300"/>

如果你觉得项目对你有帮助，欢迎打赏。

<img src="https://github.com/unfish/AI_Proxy_United/blob/master/readme/weixin.jpg?raw=true" width="300"/>
